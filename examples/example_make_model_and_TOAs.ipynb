{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PulsePortraiture Example:\n",
    "## --- Fit a spline model describing profile evolution and generate TOAs ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PSRCHIVE-style metafile listing data archives to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metafile = 'example.meta'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (0) Make fake data, if needed\n",
    "#### This uses a Gaussian-component description for making fake data, but any data will do\n",
    "##### This section can be skipped if you have some data to use, just set the metafile variable above to the right name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pplib import DataPortrait, make_fake_pulsar, make_constant_portrait  # pplib.py contains many common features\n",
    "import psrchive as pr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input profile model and ephemeris used to make fake pulsar data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ppgauss.py-style model file for fake pulsar, constructed using Gaussian components\n",
    "modelfile = 'example.gmodel'\n",
    "# The use of this ephemeris is limited (no binary params) / not so important here (only spin period really matters)\n",
    "ephemeris = 'example.par'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set parameters for fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These files will be homogenous, even though they don't need to be\n",
    "nfiles = 5       # Number of datafiles/epochs\n",
    "MJD0 = 57202.00  # Start day [MJD]\n",
    "days = 20.0      # Days between epochs\n",
    "nsub = 10        # Number of subintegrations\n",
    "npol = 1         # Number of polarization (can be 4, but will only use total intensity)\n",
    "nchan = 64       # Number of frequency channels\n",
    "nbin = 512       # Number of phase bins\n",
    "nu0 = 1500.0     # Center of the band [MHz]\n",
    "bw = 800.0       # Bandwidth [MHz]\n",
    "tsub = 60.0      # Length of subintegration [s]\n",
    "noise_std = 1.5  # Noise level of the band, per subintegration [flux units]\n",
    "dDM_mean = 3e-4  # Add in random dispersion measure offsets with this mean value\n",
    "dDM_std = 2e-4   # Add in random dispersion measure offsets with this std\n",
    "dDMs = np.random.normal(dDM_mean, dDM_std, nfiles)\n",
    "#dDMs = np.zeros(nfiles) # Uncomment this line and comment previous line for no injected dDMs\n",
    "scint = True     # Add random scintillation; scattering parameters will be read from the modelfile\n",
    "weights = np.ones([nsub, nchan]) # Change if you want to have an \"RFI\" mask\n",
    "                                 # e.g., band edges zapped:\n",
    "                                 # weights[:,:10] = weights[:,-10:] = 0.0\n",
    "                                 # e.g. first and last subints zapped:\n",
    "                                 # weights[0] = weights[-1] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses old, clunky function, but it works\n",
    "for ifile in range(nfiles):\n",
    "    start_MJD = pr.MJD(MJD0 + ifile*days)\n",
    "    make_fake_pulsar(modelfile, ephemeris, outfile='example-%d.fits'%(ifile+1),\n",
    "            nsub=nsub, npol=npol, nchan=nchan, nbin=nbin, nu0=nu0, bw=bw,\n",
    "            tsub=tsub, phase=0.0, dDM=dDMs[ifile], start_MJD=start_MJD,\n",
    "            weights=weights, noise_stds=noise_std, scales=1.0,\n",
    "            dedispersed=False, scint=scint, state='Stokes', telescope='GBT',\n",
    "            quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use psredit to set some header info in the fake data archives\n",
    "! psredit -q -m -c rcvr:name='fake_rx' -c be:name='fake_be' example-*.fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metafile\n",
    "! ls example-[0-9]*.fits > example.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Make an average portrait using ppalign.py\n",
    "#### This aligns and averages the data based on a constant phase offset plus a frequency**-2 rotation\n",
    "##### The following is equivalent to the command-line version:\n",
    "##### ppalign.py -M example.meta -I example-1.fits -T -C 15.0 -o example.port --niter 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ppalign as ppa  # Import ppalign.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Align and average archives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First make a dummy archive filled with the average profile from one fake data archive to use as the initial alignment\n",
    "dp = DataPortrait('example-1.fits', quiet=True)  # load first fake data archive as a 'DataPortait' class instance\n",
    "make_constant_portrait(\"example-1.fits\", \"example-init.fits\", profile=dp.prof, DM=0.0,\n",
    "                    dmc=False, weights=None, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The following uses an average profile as an initial guess for the alignment and iterates a few times, using the\n",
    "#   resulting average portrait as the starting alignment for the subsequent iteration\n",
    "# A frequency-averaged profile can also be used as an initial alignment\n",
    "# Another good option is to use one Gaussian component for initial alignment; from the command line (see ppalign.py -h):\n",
    "#   ppalign.py -M example.meta -g 0.1 -T -C 15.0 -o example.port --niter 3\n",
    "# The SNR_cutoff is optional, but useful when filtering out non-detections\n",
    "outfile = 'example.port'  # output average portrait name\n",
    "ppa.align_archives(metafile=metafile, initial_guess='example-init.fits', fit_dm=True,\n",
    "                   tscrunch=True, pscrunch=True, SNR_cutoff=15.0, outfile=outfile, niter=3, quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a model of profile evolution using ppspline.py\n",
    "#### This uses Principal Component Analysis to decompose the average portrait into significant eigenprofiles and fits a spline to the projection of the data onto the basis; see Pennucci (2019).\n",
    "##### The following is equivalent to the command-line version:\n",
    "##### ppspline.py -d example.port  -o example-fit.spl -N prof -s -n 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ppspline as pps  # Import ppspline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = 'example.port'  # average data portrait to model\n",
    "# Initiate class instance\n",
    "dp = pps.DataPortrait(datafile)\n",
    "dp.normalize_portrait('prof')  # This normalization is based on the mean profile and seems to work well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Have a look at the data you will model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.show_data_portrait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set some modeling parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB: normally we wouldn't set max_ncomp, but it is set here to speed things up for the fake data exercise\n",
    "max_ncomp = 3  # use None [default] if analyzing arbitrary data with an unknown number of significant eigenprofiles\n",
    "# NB: in very high S/N pulsars, the automatic smoothing algorithm may be insufficient and more finessing is necessary\n",
    "smooth = True  # [default] smoothing is recommended, but it is not the command-line default (hence the -s option above)\n",
    "snr_cutoff = 150.0  # [default] the S/N cut off for determining significant eigenprofiles\n",
    "rchi2_tol = 0.1  # [default] the tolerance around a red. chi2 of 1.0 to help the auto-smoothing of the mean/eigen profiles\n",
    "k = 3  # [default] polynomial degree of the B-splines\n",
    "sfac = 1.0  # [default] smoothing \"fudge\" factor, which will determing the smoothness of the interpolating spline\n",
    "max_nbreak = None  # [default] the maximum number of spline breakpoints; this may be used instead of sfac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be as simple as dp.make_spline_model(); arguments shown for clarity\n",
    "dp.make_spline_model(max_ncomp=max_ncomp, smooth=smooth, snr_cutoff=snr_cutoff, rchi2_tol=rchi2_tol, k=k, sfac=sfac,\n",
    "                     max_nbreak=max_nbreak, model_name=None, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Have a look at the mean profile and eigenprofiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.show_eigenprofiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Have a look at the spline curve model of profile evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.show_spline_curve_projections()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write the model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_modelfile = 'example-fit.spl'  # output model file\n",
    "dp.write_model(fitted_modelfile, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate \"wideband\" TOAs with DM measurements using pptoas.py\n",
    "#### This uses a Fourier-domain phase-gradient algorithm like Taylor (1992); see Pennucci, Demorest, Ransom (2014).\n",
    "##### The following is equivalent to the command-line version:\n",
    "##### pptoas.py -d example.meta -m example-fit.spl -o example.tim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pptoas as ppt  # Import pptoas.py\n",
    "from pplib import write_TOAs  # and the function to write TOAs from pplib.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiate class instance and get TOAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One could also use a .gmodel Gaussian model file or a smoothed average of the data as an input model\n",
    "gt = ppt.GetTOAs(metafile, fitted_modelfile)\n",
    "gt.get_TOAs()  # The default will output the TOAs at a reference frequency such that they have zero covariance w/ DM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Have a look at how one subintegration was fit by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt.show_fit(datafile=gt.datafiles[0], isub=0)  # datafile=None will just select the first datafile from the metafile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write TOAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timfile = 'example.tim'\n",
    "# There is an optional SNR_cutoff and way to append to an existing timfile\n",
    "write_TOAs(gt.TOA_list, SNR_cutoff=0.0, outfile=timfile, append=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note on measuring the TOA and DM together with scattering timescale and index; see Pennucci et al. (forthcoming) --\n",
    "#####  If you have a profile evolution model of the unscattered portrait (Gaussian-component based, or otherwise), fitting scattering is easy:\n",
    "##### pptoas.py -d example.meta -m example.gmodel -o example.tim --fit_scat\n",
    "#####  Try ppgauss.py for one way to estimate an unscattered portrait model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Tempo\n",
    "#### This is just to demonstrate the simplest possible timing\n",
    "##### The following is equivalent to the command-line version:\n",
    "##### tempo -G -f example.par example.tim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempo_utils as tu  # Import tempo_utils to do the analysis\n",
    "import matplotlib.pyplot as plt  # and pyplot for simple plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parfile = 'example.par'\n",
    "timfile = 'example.tim'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add MODE/FORMAT lines to .tim file if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment these out if FORMAT 1 and MODE 1 are already in place\n",
    "! sed -i '1s/^/FORMAT 1\\n/' example.tim\n",
    "! sed -i '1s/^/MODE 1\\n/' example.tim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add DMDATA 1 if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DMDATA 1 is necessary for tempo to make use of the DM measurements (--pp_dm on the TOA lines)\n",
    "parfile_keys = tu.parfile(parfile).keys\n",
    "if 'DMDATA' not in parfile_keys:\n",
    "    ! echo 'DMDATA 1' >> example.par"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read TOAs and run tempo with GLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toas = tu.read_toa_file(timfile)\n",
    "tu.run_tempo(toas, parfile, gls=True)  # GLS is necessary for tempo to make use of the DM measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Have a look at the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(toas.get_mjd(), toas.get_resids(), toas.get_resid_err(), fmt='kx')\n",
    "plt.xlabel('MJD')\n",
    "plt.ylabel('Residual [us]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Have a look at the DM measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(toas.get_mjd(), map(float, toas.get_flag('pp_dm')), map(float, toas.get_flag('pp_dme')), fmt='kx')\n",
    "plt.xlabel('MJD')\n",
    "plt.ylabel(r'DM [cm$^{-3}$ pc]')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
